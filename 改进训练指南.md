# 🚀 改进训练指南 - 提升模型性能

## 📊 当前情况

您的全量模型性能：
- **R² = 0.373**（偏低）
- **样本数**: 52,031
- **MAE**: 6.16

## ✨ 已实施的改进

### 1. 添加 LightGBM 支持
- ✅ 更强大的梯度提升算法
- ✅ 更快的训练速度
- ✅ 更好的拟合能力

### 2. 增强超参数配置
- ✅ `n_estimators`: 可配置树的数量（默认400 → 可达800）
- ✅ `learning_rate`: 可配置学习率（默认0.05 → 可调至0.02-0.05）
- ✅ `max_depth`: 可配置树深度（3 → 5-7）

### 3. 目标变换
- ✅ `use_log_transform`: log1p变换处理长尾分布

### 4. 诊断工具
- ✅ `scripts/diagnose_host_performance.py`: 分宿主性能分析

---

## 🎯 改进训练方案（按推荐顺序）

### 方案1️⃣: 平衡训练 + LightGBM（推荐首选）⭐

**用时**: 5-10分钟  
**特点**: 平衡各宿主，使用LightGBM，提升容量

```bash
docker-compose -f docker-compose.microservices.yml run --rm training \
  --input /data/input/training_improved_lgb.json
```

**预期提升**: R² 可能达到 0.5-0.6

---

### 方案2️⃣: 平衡训练 + LightGBM + log变换

**用时**: 5-10分钟  
**特点**: 额外处理表达值长尾分布

```bash
docker-compose -f docker-compose.microservices.yml run --rm training \
  --input /data/input/training_improved_lgb_log.json
```

**适用场景**: 如果表达值分布跨度大（例如0-1000+）

---

### 方案3️⃣: 主要宿主专注训练

**用时**: 8-15分钟  
**特点**: 只训练E_coli/Human/Mouse，避免少样本宿主干扰

```bash
docker-compose -f docker-compose.microservices.yml run --rm training \
  --input /data/input/training_improved_main_hosts.json
```

**预期提升**: R² 可能达到 0.55-0.7（针对这三个宿主）

---

### 方案4️⃣: 全量高容量训练（最强性能）

**用时**: 20-40分钟  
**特点**: 全部52k样本，最高容量模型

```bash
docker-compose -f docker-compose.microservices.yml run --rm training \
  --input /data/input/training_improved_full_lgb.json
```

**预期提升**: R² 可能达到 0.5-0.65

---

## 📋 完整执行步骤

### 第1步: 重建训练容器（添加LightGBM）

```bash
cd /mnt/c/Users/xiayh17/Projects/coursepicker_starter/coursepicker/codon_verifier_ext

# 重建容器
docker-compose -f docker-compose.microservices.yml build training
```

**用时**: 2-5分钟（首次构建）

---

### 第2步: 运行改进训练

**推荐**: 先运行方案1（平衡+LightGBM）

```bash
docker-compose -f docker-compose.microservices.yml run --rm training \
  --input /data/input/training_improved_lgb.json
```

---

### 第3步: 诊断性能

训练完成后，使用诊断脚本分析各宿主表现：

```bash
python3 scripts/diagnose_host_performance.py \
  --model models/improved_lgb_model.pkl \
  --data data/converted/merged_dataset.jsonl \
  --output data/output/diagnosis_improved_lgb.json
```

**输出示例**:
```
E_coli              :  18780 样本
  R² 分数:       0.6234
  MAE:           4.23
  RMSE:          5.67

Human               :  13346 样本
  R² 分数:       0.5812
  MAE:           5.45
  RMSE:          7.12
```

---

### 第4步: 对比性能

```bash
# 对比旧模型
python3 scripts/diagnose_host_performance.py \
  --model models/full_multihost_model.pkl \
  --data data/converted/merged_dataset.jsonl

# 对比新模型
python3 scripts/diagnose_host_performance.py \
  --model models/improved_lgb_model.pkl \
  --data data/converted/merged_dataset.jsonl
```

---

## 🔍 性能诊断工具

### 分宿主诊断

```bash
python3 scripts/diagnose_host_performance.py \
  --model models/YOUR_MODEL.pkl \
  --data data/converted/merged_dataset.jsonl \
  --output data/output/diagnosis_result.json
```

**输出信息**:
- 各宿主的 R²、MAE、RMSE
- 真实值与预测值的统计分布
- Sigma（不确定性）估计

---

## 💡 配置参数说明

### `surrogate_config` 参数

| 参数 | 默认值 | 推荐范围 | 说明 |
|------|--------|----------|------|
| `n_estimators` | 400 | 400-800 | 树的数量，越多越强但训练越慢 |
| `learning_rate` | 0.05 | 0.02-0.05 | 学习率，越小越稳定但需要更多树 |
| `max_depth` | 5 | 5-7 | 树深度，越深越能拟合复杂模式 |
| `use_log_transform` | false | true/false | 是否使用log1p变换目标值 |
| `quantile_hi` | 0.9 | 0.84-0.95 | 上分位数，用于估计不确定性 |
| `test_size` | 0.15 | 0.1-0.2 | 测试集比例 |

### `data_config` 参数

| 参数 | 说明 |
|------|------|
| `balance_hosts` | `true`: 平衡各宿主样本数 |
| `max_samples_per_host` | 每个宿主最大样本数 |
| `filter_reviewed_only` | `true`: 只用审核过的条目 |
| `target_hosts` | 指定训练的宿主列表 |

---

## 🎨 自定义配置示例

复制并修改配置：

```bash
# 复制基础配置
cp data/input/training_improved_lgb.json data/input/my_custom_training.json

# 编辑配置
nano data/input/my_custom_training.json
```

**示例修改**:
```json
{
  "surrogate_config": {
    "n_estimators": 1000,      // 增加到1000棵树
    "learning_rate": 0.02,      // 降低学习率
    "max_depth": 8,             // 增加深度到8
    "use_log_transform": true   // 启用log变换
  }
}
```

---

## 📊 期望性能提升

根据改进措施，预期性能提升：

| 方案 | 当前R² | 预期R² | 提升幅度 |
|------|--------|--------|----------|
| 原始全量 | 0.373 | - | 基线 |
| 方案1 (平衡+LGB) | 0.373 | 0.5-0.6 | +35-60% |
| 方案2 (平衡+LGB+log) | 0.373 | 0.5-0.65 | +35-75% |
| 方案3 (主要宿主) | 0.373 | 0.55-0.7 | +48-88% |
| 方案4 (全量高容量) | 0.373 | 0.5-0.65 | +35-75% |

**注意**: 实际提升取决于数据质量和分布

---

## 🔧 故障排除

### 问题1: LightGBM未安装

**症状**: 训练仍使用sklearn GradientBoosting

**解决**:
```bash
# 确认重建了容器
docker-compose -f docker-compose.microservices.yml build training

# 验证LightGBM可用
docker-compose -f docker-compose.microservices.yml run --rm training python3 -c "import lightgbm; print('LightGBM version:', lightgbm.__version__)"
```

### 问题2: 内存不足

**症状**: 训练中断或系统卡死

**解决**: 减少样本数
```json
"config": {
  "max_samples_per_host": 2000,  // 减少到2000
  "max_samples": 10000            // 总数限制10000
}
```

### 问题3: 训练时间太长

**解决**: 减少超参数
```json
"surrogate_config": {
  "n_estimators": 400,  // 减少到400
  "max_depth": 5        // 深度降到5
}
```

---

## 📈 性能优化建议

### 如果 R² 仍然较低 (< 0.5)

1. **检查数据质量**
   ```bash
   # 查看表达值分布
   python3 -c "
   import json
   import numpy as np
   values = []
   with open('data/converted/merged_dataset.jsonl') as f:
       for line in f:
           r = json.loads(line)
           expr = r.get('expression', {})
           val = expr.get('value', 0) if isinstance(expr, dict) else expr
           values.append(float(val))
   print(f'最小值: {np.min(values):.2f}')
   print(f'最大值: {np.max(values):.2f}')
   print(f'均值: {np.mean(values):.2f}')
   print(f'中位数: {np.median(values):.2f}')
   print(f'标准差: {np.std(values):.2f}')
   "
   ```

2. **尝试宿主特定模型**
   ```bash
   docker-compose -f docker-compose.microservices.yml run --rm training \
     --input /data/input/training_real_host_specific.json
   ```

3. **启用log变换** (如果表达值跨度大)

4. **增加特征工程** (需要修改代码添加更多特征)

---

## ✅ 推荐执行流程

```bash
# 1. 重建容器（一次性）
docker-compose -f docker-compose.microservices.yml build training

# 2. 方案1：平衡训练 + LightGBM
docker-compose -f docker-compose.microservices.yml run --rm training \
  --input /data/input/training_improved_lgb.json

# 3. 诊断性能
python3 scripts/diagnose_host_performance.py \
  --model models/improved_lgb_model.pkl \
  --data data/converted/merged_dataset.jsonl

# 4. 如果表现好，继续尝试log变换
docker-compose -f docker-compose.microservices.yml run --rm training \
  --input /data/input/training_improved_lgb_log.json

# 5. 再次诊断
python3 scripts/diagnose_host_performance.py \
  --model models/improved_lgb_log_model.pkl \
  --data data/converted/merged_dataset.jsonl

# 6. 选择表现最好的模型用于生产
```

---

## 🎉 预期结果

完成改进后，你应该得到：

✅ **R² 提升到 0.5+**（从0.373提升35%+）  
✅ **MAE 降低**（更准确的预测）  
✅ **各宿主性能报告**（知道哪些宿主表现好）  
✅ **多个可选模型**（针对不同场景）

---

**立即开始改进！** 🚀

```bash
# 一键开始
cd /mnt/c/Users/xiayh17/Projects/coursepicker_starter/coursepicker/codon_verifier_ext && \
docker-compose -f docker-compose.microservices.yml build training && \
docker-compose -f docker-compose.microservices.yml run --rm training \
  --input /data/input/training_improved_lgb.json
```

